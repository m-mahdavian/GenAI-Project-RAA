{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11301610,"sourceType":"datasetVersion","datasetId":7067777}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Reviewer Assistant Agent (RAA)\n\n**Overview:**\n\nThis Python script implements a \"Reviewer Assistant Agent\" (RAA) designed to automate key parts of the scientific manuscript peer-review process. Utilizing the LangChain framework and an OpenAI language model (e.g., gpt-4.1-mini), the agent analyzes a submitted manuscript (in PDF format), extracts specific quantitative findings, searches for similar articles online, extracts comparable data from those articles, and presents a structured comparison. The entire workflow is orchestrated by a LangChain AgentExecutor managing a suite of custom tools. This script provides a powerful, automated starting point for reviewers looking to quickly understand a manuscript's key contributions and compare them against relevant online literature.\n\n**Goal:**\n\nThe primary goal is to assist scientific reviewers by:\n\nProviding a concise summary of a manuscript's core findings.\n\nAutomatically extracting predefined quantitative metrics (Corrosion Inhibition Efficiency %, Impedance ohm.cm², Adhesion Strength MPa) from the manuscript.\n\nIdentifying potentially relevant existing literature via web search based on the manuscript's title.\n\nAttempting to extract the same quantitative metrics from found online articles (PDFs or HTML) for quick comparison against the submitted manuscript's results.\n\n**Core Technologies:**\n\nOrchestration: LangChain AgentExecutor with create_openai_functions_agent.\n\nLLM: OpenAI ChatOpenAI (model configurable, e.g., gpt-4.1-mini).\n\nCustom Tools: LangChain BaseTool subclasses for specific tasks (loading, summarizing, extracting, searching, processing URLs).\n\nTool Schemas: Pydantic V1 (BaseModel, Field) for defining tool input arguments.\n\nWeb Search: duckduckgo-search library.\n\nPDF Handling: PyPDFLoader (from langchain_community).\n\nWeb Interaction: requests library for downloading, BeautifulSoup4 for HTML parsing.\n\nText Processing: LangChain RecursiveCharacterTextSplitter, load_summarize_chain.\n\nData Handling: pandas for displaying results.\n\nExecution: Standard Python 3, argparse for command-line arguments, logging.\n\nThis script is mainly created by **Google AI Studio**","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade --no-cache-dir duckduckgo-search --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:42:52.785494Z","iopub.execute_input":"2025-04-15T20:42:52.785789Z","iopub.status.idle":"2025-04-15T20:42:59.988192Z","shell.execute_reply.started":"2025-04-15T20:42:52.785768Z","shell.execute_reply":"2025-04-15T20:42:59.986755Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install --upgrade --no-cache-dir langchain langchain_openai openai pypdf pandas google-search-results beautifulsoup4 kaggle googlesearch-python langchain_community requests lxml --quiet\n\nprint(\"Libraries installed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:42:59.990195Z","iopub.execute_input":"2025-04-15T20:42:59.991202Z","iopub.status.idle":"2025-04-15T20:43:19.824188Z","shell.execute_reply.started":"2025-04-15T20:42:59.991160Z","shell.execute_reply":"2025-04-15T20:43:19.823006Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.8/644.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.3/187.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.6/433.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nnilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mLibraries installed.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# --- START OF IMPORT SECTION ---\n\nimport os\nimport re\nimport sys\nimport time\nimport json\nimport argparse\nimport logging\nimport traceback\nfrom tempfile import NamedTemporaryFile, TemporaryDirectory\nfrom urllib.parse import urljoin, urlparse\n\n# --- Dependency Imports with Error Handling ---\n\nlog = logging.getLogger(__name__) # Assuming logger is set up later\n\ntry:\n    # Core Third-Party Libraries\n    import pandas as pd\n    import requests\n    from bs4 import BeautifulSoup\n    log.info(\"Successfully imported: pandas, requests, bs4\")\nexcept ImportError as e:\n    log.critical(f\"Error: Missing core third-party library: {e}\")\n    log.critical(\"Please install requirements: pip install pandas requests beautifulsoup4 lxml\")\n    traceback.print_exc()\n    exit(1)\n\ntry:\n    # Google Search (Optional)\n    from googlesearch import search\n    log.info(\"Successfully imported: googlesearch\")\nexcept ImportError:\n    log.warning(\"Could not import googlesearch. Search functionality will be disabled.\")\n    log.warning(\"You can install it using: pip install googlesearch-python\")\n    search = None # Define search as None so the script can proceed without it\n\ntry:\n    # OpenAI SDK\n    import openai # Although langchain_openai wraps it, direct import check is good\n    from langchain_openai import ChatOpenAI\n    log.info(\"Successfully imported: openai, langchain_openai.ChatOpenAI\")\nexcept ImportError as e:\n    log.critical(f\"Error: Missing OpenAI or Langchain OpenAI integration: {e}\")\n    log.critical(\"Please install requirements: pip install openai langchain_openai\")\n    traceback.print_exc()\n    exit(1)\n\ntry:\n    # LangChain Core Components\n    from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n    from langchain_core.tools import BaseTool\n    from langchain_core.documents import Document # Corrected from langchain.docstore.document\n    from langchain_core.messages import AIMessage, HumanMessage\n    # Pydantic v1 is often needed for Langchain schemas\n    from langchain.pydantic_v1 import BaseModel, Field\n    log.info(\"Successfully imported: LangChain core prompts, tools, documents, messages, pydantic_v1\")\n\n    # Ensure BaseModel and Field are recognized immediately after import\n    assert BaseModel is not None\n    assert Field is not None\n    log.info(\"Confirmed BaseModel and Field are loaded.\")\n\nexcept ImportError as e:\n    log.critical(f\"Error: Missing core LangChain library: {e}\")\n    log.critical(\"This often indicates an incomplete or corrupted installation.\")\n    log.critical(\"Try reinstalling: pip install --upgrade --force-reinstall langchain langchain-core\")\n    traceback.print_exc()\n    exit(1)\nexcept AssertionError:\n    log.critical(\"Error: BaseModel or Field not recognized immediately after import. Check installation.\")\n    traceback.print_exc()\n    exit(1)\n\n\ntry:\n    # LangChain Community Components (Loaders, Splitters)\n    from langchain_community.document_loaders import PyPDFLoader\n    from langchain.text_splitter import RecursiveCharacterTextSplitter # Often in top-level langchain\n    log.info(\"Successfully imported: LangChain community loaders, text_splitter\")\nexcept ImportError as e:\n    log.critical(f\"Error: Missing LangChain community or text_splitter component: {e}\")\n    log.critical(\"Please install requirements: pip install langchain_community pypdf\")\n    traceback.print_exc()\n    exit(1)\n\ntry:\n    from duckduckgo_search import DDGS\n    log.info(\"Successfully imported: duckduckgo_search\")\n    ddgs_search = DDGS()\nexcept ImportError:\n    log.warning(\"Could not import duckduckgo_search. Install with 'pip install duckduckgo-search'\")\n    ddgs_search = None\n    \ntry:\n    # LangChain Chains and Agents\n    from langchain.chains.summarize import load_summarize_chain\n    from langchain.agents import AgentExecutor, create_openai_functions_agent\n    log.info(\"Successfully imported: LangChain chains, agents\")\nexcept ImportError as e:\n    # Check specifically for the BaseCache error if it occurs here\n    if 'BaseCache' in str(e):\n         log.critical(f\"Error: Missing component likely related to LangChain caching/runnables: {e}\")\n         log.critical(\"This points to an issue within 'langchain-core'.\")\n         log.critical(\"Ensure 'langchain-core' is installed correctly and is compatible.\")\n         log.critical(\"Try reinstalling: pip install --upgrade --force-reinstall langchain-core langchain\")\n    else:\n        log.critical(f\"Error: Missing LangChain chains or agents component: {e}\")\n        log.critical(\"Please ensure langchain is fully installed.\")\n    traceback.print_exc()\n    exit(1)\n\n# --- Logging Setup ---\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlog = logging.getLogger(__name__)\n\n# --- Constants and Configuration ---\n# These can be overridden by command-line arguments\nDEFAULT_LLM_MODEL = \"gpt-4.1-mini\"\nDEFAULT_MAX_SEARCH_RESULTS = 10\nDEFAULT_MAX_SIMILAR_ARTICLES_TO_PROCESS = 5\nDEFAULT_DOWNLOAD_TIMEOUT = 25\nDEFAULT_MAX_CHARS_FOR_EXTRACTION = 25000\nHEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n\n# --- Helper Functions (mostly for tools) ---\n\ndef load_pdf_text_internal(pdf_path):\n    \"\"\"Loads text content from a PDF file. Returns (full_text, docs_list)\n       Internal version for tools, raises errors on failure.\"\"\"\n    try:\n        log.info(f\"Loading PDF: {pdf_path}\")\n        if not os.path.exists(pdf_path):\n             raise FileNotFoundError(f\"PDF file not found at: {pdf_path}\")\n        loader = PyPDFLoader(pdf_path, extract_images=False)\n        docs = loader.load()\n        if not docs:\n             log.warning(f\"PyPDFLoader loaded 0 pages from {pdf_path}.\")\n             return None, [] # Return empty list for docs\n\n        cleaned_pages = []\n        for doc in docs:\n             cleaned_content = doc.page_content.replace('\\x00', '').strip()\n             cleaned_pages.append(cleaned_content)\n\n        full_text = \"\\n\".join(filter(None, cleaned_pages))\n\n        if not full_text:\n            log.warning(f\"PDF loaded but resulted in empty text content after cleaning: {pdf_path}\")\n            # Still return the loaded docs object if it exists, even if text is empty\n            return None, docs\n\n        log.info(f\"Successfully loaded text from: {pdf_path} ({len(docs)} pages, {len(full_text)} chars)\")\n        return full_text, docs\n    except Exception as e:\n        log.error(f\"Error loading PDF {pdf_path}: {type(e).__name__} - {e}\", exc_info=False) # Log error without traceback for cleaner tool output\n        raise # Re-raise the exception for the tool/agent to handle\n\ndef extract_text_from_html_internal(html_content):\n    \"\"\"Extracts plain text from HTML content.\"\"\"\n    try:\n        soup = BeautifulSoup(html_content, 'lxml')\n        for script_or_style in soup([\"script\", \"style\"]):\n            script_or_style.decompose()\n        text = soup.get_text(separator='\\n', strip=True)\n        text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n        log.info(f\"Extracted ~{len(text)} characters of text from HTML.\")\n        return text\n    except Exception as e:\n        log.error(f\"Error extracting text from HTML: {e}\", exc_info=False)\n        return None # Return None on failure, tool should report this\n\ndef parse_llm_extraction_internal(llm_output_text):\n    \"\"\"Parses the LLM text output using regex for key data.\"\"\"\n    data = {\n        'corrosion_inhibition_%': 'Not Found',\n        'impedance_ohm_cm2': 'Not Found',\n        'adhesion_MPa': 'Not Found'\n    }\n    patterns = {\n        'corrosion_inhibition_%': r\"Corrosion Inhibition \\(%\\):\\s*([\\d\\.]+%?|Not Found|N/A|-)\",\n        'impedance_ohm_cm2': r\"Impedance \\((?:ohm\\.cm2|ꭥ\\.cm2)\\):\\s*(.*?)(?:\\n|Adhesion|$)\",\n        'adhesion_MPa': r\"Adhesion \\(MPa\\):\\s*([\\d\\.]+|Not Found|N/A|-)\"\n    }\n\n    for key, pattern in patterns.items():\n        match = re.search(pattern, llm_output_text, re.IGNORECASE | re.MULTILINE | re.DOTALL)\n        if match:\n            value = match.group(1).strip()\n            if value.lower() in ['not found', 'n/a', '-'] or not value:\n                data[key] = 'Not Found'\n            else:\n                if key == 'impedance_ohm_cm2':\n                     value = re.sub(r'\\s+', ' ', value).strip('., ').strip()\n                     if not value or value.lower() in ['not found', 'n/a', '-']:\n                          data[key] = 'Not Found'\n                     else:\n                         num_match = re.search(r\"([-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?)\", value)\n                         num_val = num_match.group(1) if num_match else 'N/A'\n                         # Keep parsed num in value for clarity, but could simplify\n                         data[key] = f\"{value} (parsed num: {num_val})\"\n                else:\n                    num_match = re.search(r\"([-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?)\", value)\n                    if num_match:\n                        data[key] = num_match.group(1).strip()\n                    else:\n                        data[key] = 'Not Found (parse failed)'\n                        log.info(f\"Regex matched for {key} but couldn't parse number from '{value}'\")\n        else:\n             data[key] = 'Not Found (pattern mismatch)'\n\n    log.info(f\"Parsed LLM Extraction Output: {data}\")\n    return data\n\ndef download_pdf_internal(url, save_dir, timeout):\n    \"\"\"Attempts direct PDF download. Returns (pdf_path, response_object_or_None)\"\"\"\n    os.makedirs(save_dir, exist_ok=True)\n    pdf_path = None\n    response = None\n    try:\n        log.info(f\"Attempting direct PDF download from: {url}\")\n        response = requests.get(url, stream=True, timeout=timeout, headers=HEADERS, allow_redirects=True)\n        response.raise_for_status()\n        content_type = response.headers.get('Content-Type', '').lower()\n        is_pdf_content = ('application/pdf' in content_type or\n                          '.pdf' in urlparse(url).path.lower() or\n                          'pdf' in response.headers.get('Content-Disposition', '').lower())\n\n        if is_pdf_content and response.status_code == 200:\n            content_length_str = response.headers.get('content-length')\n            if content_length_str is not None and int(content_length_str) == 0:\n                 log.warning(f\"Content-Length is 0 for {url}. Skipping download.\")\n                 return None, response\n\n            with NamedTemporaryFile(delete=False, suffix=\".pdf\", dir=save_dir) as temp_file:\n                pdf_path = temp_file.name\n                bytes_downloaded = 0\n                for chunk in response.iter_content(chunk_size=8192):\n                    temp_file.write(chunk)\n                    bytes_downloaded += len(chunk)\n\n            if bytes_downloaded < 1024: # Check if PDF is suspiciously small\n                 log.warning(f\"Downloaded PDF {pdf_path} is small ({bytes_downloaded} bytes). May be invalid.\")\n\n            try:\n                 loader_check = PyPDFLoader(pdf_path, extract_images=False)\n                 # Try loading only the first page for a quicker check\n                 loader_check.load() # If it fails, raises an exception\n                 log.info(f\"Successfully downloaded and verified PDF ({bytes_downloaded} bytes) to: {pdf_path}\")\n                 return pdf_path, response\n            except Exception as pdf_err:\n                 log.warning(f\"Downloaded file {pdf_path} failed PDF verification: {pdf_err}. Removing.\")\n                 if pdf_path and os.path.exists(pdf_path): os.remove(pdf_path)\n                 return None, response # Return None path, but keep response obj\n        else:\n            log.info(f\"URL does not appear to be a direct PDF or has error. Status: {response.status_code}, Content-Type: {content_type}\")\n            return None, response\n\n    except requests.exceptions.Timeout:\n        log.warning(f\"Timeout occurred downloading {url}\")\n        return None, None\n    except requests.exceptions.HTTPError as http_err:\n        log.warning(f\"HTTP Error for {url}: {http_err}\")\n        return None, getattr(http_err, 'response', None)\n    except requests.exceptions.RequestException as e:\n        log.warning(f\"Failed download/access for {url}: {e}\")\n        return None, None\n    except Exception as e:\n        log.error(f\"Unexpected error during direct download {url}: {type(e).__name__} {e}\", exc_info=False)\n        return None, response\n\ndef find_and_download_pdf_from_html_internal(page_url, page_content, save_dir, timeout):\n    \"\"\"Parses HTML to find PDF links and attempts download.\"\"\"\n    log.info(f\"Scanning HTML from {page_url} for PDF links.\")\n    soup = BeautifulSoup(page_content, 'lxml')\n    pdf_links = []\n    found_links = set()\n\n    for a_tag in soup.find_all('a', href=True):\n        href = a_tag['href'].strip()\n        if not href or href.startswith('#') or href.lower().startswith('javascript:'):\n            continue\n\n        href_lower = href.lower()\n        link_text = a_tag.get_text(strip=True).lower()\n\n        is_likely_pdf = (\n            href_lower.endswith('.pdf') or\n            '/pdf/' in href_lower or any(kw in href_lower for kw in ['download=pdf', 'downloadpdf', 'articlepdf', 'fulltextpdf', 'viewpdf']) or\n            link_text in ['pdf', 'full text pdf', 'download pdf', '[pdf]', 'article pdf', 'view pdf', 'get pdf'] or\n            (a_tag.get('class') and any('pdf' in c.lower() for c in a_tag.get('class', []))) or\n            (a_tag.get('id') and 'pdf' in a_tag.get('id','').lower())\n        )\n\n        if is_likely_pdf:\n            try:\n                pdf_url = urljoin(page_url, href)\n                parsed_url = urlparse(pdf_url)\n                if parsed_url.scheme in ['http', 'https'] and pdf_url != page_url and pdf_url not in found_links:\n                    if '.pdf' in pdf_url.lower() or any(kw in pdf_url.lower() for kw in ['download', 'content', 'fulltext', 'article', 'view']):\n                         log.info(f\"Found potential PDF link: {pdf_url}\")\n                         pdf_links.append(pdf_url)\n                         found_links.add(pdf_url)\n            except Exception as parse_err:\n                 log.warning(f\"Skipping invalid link '{href}': {parse_err}\")\n\n    pdf_links.sort(key=lambda x: not (x.lower().endswith('.pdf') or 'download' in x.lower()), reverse=True)\n\n    if not pdf_links:\n        log.info(\"No likely PDF links found in HTML.\")\n        return None\n\n    log.info(f\"Found {len(pdf_links)} potential links. Attempting download...\")\n    for pdf_url in pdf_links:\n        time.sleep(1.0)\n        log.info(f\"Attempting download from HTML link: {pdf_url}\")\n        downloaded_path, _ = download_pdf_internal(pdf_url, save_dir, timeout)\n        if downloaded_path:\n            log.info(f\"Successfully downloaded PDF from HTML link: {pdf_url}\")\n            return downloaded_path\n\n    log.info(\"Tried all potential PDF links from HTML, none worked.\")\n    return None\n\n# --- Custom LangChain Tools ---\n\nclass LoadManuscriptInput(BaseModel):\n    pdf_path: str = Field(description=\"The file path to the manuscript PDF.\")\n\nclass LoadManuscriptTool(BaseTool):\n    name: str = \"load_manuscript\"\n    description: str = \"Loads the text content from a PDF and extracts page data. Returns a dictionary with 'full_text' and 'docs_data' (a list of dicts, each with 'page_content' and 'metadata'). Critical first step.\" # <-- UPDATED description\n    args_schema: type[BaseModel] = LoadManuscriptInput\n\n    def _run(self, pdf_path: str) -> dict:\n        try:\n            full_text, docs = load_pdf_text_internal(pdf_path)\n            # Convert Document objects to simple dicts for serialization\n            docs_data = []\n            if docs:\n                docs_data = [{\"page_content\": doc.page_content, \"metadata\": doc.metadata} for doc in docs]\n\n            return {\n                \"full_text\": full_text if full_text else \"\",\n                \"docs_data\": docs_data # <-- RETURN docs_data instead of docs\n                }\n        except Exception as e:\n            log.error(f\"LoadManuscriptTool failed: {e}\", exc_info=False)\n            return {\"error\": f\"Failed to load manuscript '{os.path.basename(pdf_path)}': {e}\"}\n\nclass SummarizeManuscriptInput(BaseModel):\n    # Change from list[Document] to list[dict]\n    docs_data: list[dict] = Field(description=\"A list of dictionaries, each with 'page_content' and 'metadata', obtained from 'load_manuscript'.\")\n    \nclass SummarizeManuscriptTool(BaseTool):\n    name: str = \"summarize_manuscript\"\n    description: str = \"Generates a concise summary of the manuscript using its extracted page data.\" # <-- Slightly updated description\n    args_schema: type[BaseModel] = SummarizeManuscriptInput # Uses the updated input schema\n    llm: ChatOpenAI\n\n    # Change the input parameter name and type\n    def _run(self, docs_data: list[dict]) -> str: # <-- CHANGED parameter\n        if not self.llm:\n            log.error(\"SummarizeManuscriptTool: LLM not initialized.\")\n            return \"Error: LLM not initialized for summarization.\"\n        if not docs_data:\n            log.error(\"SummarizeManuscriptTool: No document data provided.\")\n            return \"Error: No document data provided for summarization.\"\n\n        try:\n            log.info(\"Reconstructing Document objects for summarization...\")\n            # Reconstruct Document objects from the dictionaries\n            reconstructed_docs = [Document(page_content=d.get('page_content',''), metadata=d.get('metadata',{})) for d in docs_data] # <-- RECONSTRUCT docs\n\n            if not reconstructed_docs:\n                 log.error(\"SummarizeManuscriptTool: Failed to reconstruct documents from data.\")\n                 return \"Error: Failed to reconstruct documents from provided data.\"\n\n            log.info(\"Generating summary...\")\n            summary_chain = load_summarize_chain(self.llm, chain_type=\"map_reduce\")\n            text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=500)\n            # Use the reconstructed documents\n            split_docs = text_splitter.split_documents(reconstructed_docs) # <-- Use reconstructed_docs\n\n            if not split_docs:\n                 log.error(\"SummarizeManuscriptTool: Document splitting resulted in no chunks.\")\n                 return \"Error: Document splitting resulted in no chunks for summary.\"\n\n            summary_result = summary_chain.invoke(split_docs)\n            summary = summary_result.get(\"output_text\", \"Summary generation failed.\")\n            log.info(\"Summary generated successfully.\")\n            return summary\n        except Exception as e:\n            log.error(f\"Error during summarization: {e}\", exc_info=False)\n            return f\"Error during summarization: {e}\"\n            \n\nclass ExtractMetricsInput(BaseModel):\n    text_content: str = Field(description=\"The text content from which to extract data.\")\n    source_type: str = Field(description=\"Description of the source (e.g., 'Manuscript PDF', 'Web Article PDF', 'Web Article HTML').\")\n    max_chars: int = Field(default=DEFAULT_MAX_CHARS_FOR_EXTRACTION, description=\"Max characters of text_content to analyze.\")\n\nclass ExtractMetricsTool(BaseTool):\n    name: str = \"extract_key_metrics\"\n    description: str = \"Extracts specific quantitative data (Corrosion Inhibition %, Impedance ohm.cm2, Adhesion MPa) from the provided text using an LLM. Returns a dictionary of extracted values.\"\n    args_schema: type[BaseModel] = ExtractMetricsInput\n    llm: ChatOpenAI = Field(default=None)\n\n    def _run(self, text_content: str, source_type: str, max_chars: int = DEFAULT_MAX_CHARS_FOR_EXTRACTION) -> dict:\n        if not self.llm:\n            log.error(\"ExtractMetricsTool: LLM not initialized.\")\n            return {\"error\": \"LLM not initialized for extraction.\"}\n        if not text_content:\n            log.warning(f\"ExtractMetricsTool: No text content provided for extraction from {source_type}.\")\n            return {\"error\": f\"No text content provided for extraction from {source_type}.\"}\n\n        extraction_prompt_template = \"\"\"\n        Analyze the following text from a scientific paper ({source_type}). Extract the following specific quantitative data points if present. Look carefully throughout the text, especially in results, discussion, abstract, and conclusion sections. If a value is explicitly mentioned, report it. If not found, state 'Not Found'. Provide only the numerical value (e.g., 95.5, 1.2E6, 15.3) or 'Not Found'. Ensure units are implicitly ohm.cm2 for impedance unless otherwise stated in the value itself.\n\n        1.  **Corrosion Inhibition Efficiency (%):** Look for 'Corrosion Inhibition Efficiency', 'Inhibition Efficiency', or 'IE%'. Report the highest or most representative value. [Value or 'Not Found']\n        2.  **Impedance Magnitude (ohm.cm2 or ꭥ.cm2):** Look for impedance values, often associated with EIS results (e.g., Z_real, |Z|, R_ct, R_p) reported in Ohm.cm² (or kΩ.cm², MΩ.cm² - include units if not base). Report a key representative value (e.g., low frequency, after exposure, highest resistance). [Value (include units if not base ohm.cm2) or 'Not Found']\n        3.  **Adhesion Strength (MPa):** Look for results from pull-off, scratch, or similar adhesion tests reported in MPa. [Value or 'Not Found']\n\n        Format the output strictly as follows, one item per line, using the exact keys:\n        Corrosion Inhibition (%): [Value or 'Not Found']\n        Impedance (ohm.cm2): [Value or 'Not Found']\n        Adhesion (MPa): [Value or 'Not Found']\n\n        Text Snippet (first {max_chars} chars):\n        \"{text}\"\n\n        Extracted Data:\n        \"\"\"\n        extraction_prompt = PromptTemplate(\n            template=extraction_prompt_template,\n            input_variables=[\"text\", \"source_type\", \"max_chars\"]\n        )\n\n        try:\n            log.info(f\"Requesting LLM extraction from {source_type}...\")\n            text_snippet = text_content[:max_chars]\n\n            extraction_query = extraction_prompt.format(text=text_snippet, source_type=source_type, max_chars=max_chars)\n            extraction_response = self.llm.invoke(extraction_query)\n            extracted_data_text = extraction_response.content\n            log.info(f\"LLM extraction response received for {source_type}.\")\n\n            extracted_values = parse_llm_extraction_internal(extracted_data_text)\n            extracted_values['status'] = 'Extraction Attempted'\n            if any(v not in ['Not Found', 'N/A', 'Extraction Error', 'No Text', 'LLM Error', 'Not Found (parse failed)', 'Not Found (pattern mismatch)'] and v is not None for v in extracted_values.values()):\n                 extracted_values['status'] = 'Extraction Successful (Found Values)'\n            return extracted_values\n\n        except Exception as e:\n            log.error(f\"Error during LLM data extraction from {source_type}: {e}\", exc_info=False)\n            return {\n                'corrosion_inhibition_%': 'LLM Error',\n                'impedance_ohm_cm2': 'LLM Error',\n                'adhesion_MPa': 'LLM Error',\n                'status': f'LLM Error ({type(e).__name__})'\n            }\n\nclass SearchSimilarArticlesInput(BaseModel):\n    query: str = Field(description=\"The search query, typically the manuscript title.\")\n    num_results: int = Field(description=\"Maximum number of search results to return.\")\n\nclass SearchSimilarArticlesTool(BaseTool):\n    name: str = \"search_similar_articles\"\n    description: str = \"Performs a DuckDuckGo search for articles similar to the manuscript based on a query (usually the title). Returns a list of URLs.\"\n    args_schema: type[BaseModel] = SearchSimilarArticlesInput\n\n    def _run(self, query: str, num_results: int) -> dict:\n        if not ddgs_search:\n            log.error(\"DuckDuckGo search library not available.\")\n            return {\"error\": \"DuckDuckGo search library not available.\"}\n\n        urls = []\n        effective_max = num_results if num_results > 0 else 10 # DDGS uses max_results\n\n        log.info(f\"Searching DuckDuckGo for: '{query}' (Max results: {effective_max})\")\n        try:\n            # Use ddgs.text() which returns dictionaries with 'href'\n            search_results = ddgs_search.text(\n                query,\n                region='wt-wt', # World-wide\n                safesearch='off',\n                max_results=effective_max\n            )\n\n            if search_results:\n                urls = [result['href'] for result in search_results if 'href' in result]\n            else:\n                urls = [] # Explicitly empty if no results\n\n            log.info(f\"Found {len(urls)} potential URLs via DuckDuckGo.\")\n            return {\"urls\": urls}\n\n        except Exception as e:\n             # DDG errors might be different, keep generic for now\n             error_message = f\"Error during DuckDuckGo search: {type(e).__name__} - {e}\"\n             log.error(error_message, exc_info=False)\n             return {\"error\": error_message, \"urls\": []}\n            \n\nclass ProcessWebArticleInput(BaseModel):\n    url: str = Field(description=\"The URL of the web article to process.\")\n\nclass ProcessWebArticleTool(BaseTool):\n    name :str = \"process_web_article\"\n    description :str = \"Processes a single web article URL. Attempts to download a PDF (directly or via HTML links), extracts text, and then extracts key metrics (Corrosion Inhibition %, Impedance ohm.cm2, Adhesion MPa). Returns a dictionary with the URL, processing status, and extracted data.\"\n    args_schema: type[BaseModel] = ProcessWebArticleInput\n    metrics_extractor: ExtractMetricsTool = Field(default=None)\n    download_dir: str = Field(...) # Make required\n    timeout: int = Field(...) # Make required\n\n    def _run(self, url: str) -> dict:\n        if not self.metrics_extractor:\n             log.error(\"ProcessWebArticleTool: Metrics extractor tool not provided.\")\n             return {\"url\": url, \"status\": \"Error: Metrics extractor tool not provided.\", \"data\": {}}\n\n        log.info(f\"--- Processing URL: {url} ---\")\n        pdf_path = None\n        response_obj = None\n        article_text = None\n        extracted_data = {}\n        status = \"Processing Started\"\n        source_type = \"N/A\"\n        # Initialize result structure\n        final_result = {\n            'url': url,\n            'status': status,\n            'corrosion_inhibition_%': 'N/A',\n            'impedance_ohm_cm2': 'N/A',\n            'adhesion_MPa': 'N/A'\n        }\n\n        try:\n            # Attempt 1: Direct Download PDF\n            pdf_path, response_obj = download_pdf_internal(url, self.download_dir, self.timeout)\n\n            if pdf_path:\n                try:\n                    article_text, _ = load_pdf_text_internal(pdf_path)\n                    if article_text:\n                        status = \"PDF Downloaded & Text Loaded\"\n                        source_type = \"PDF\"\n                    else:\n                        status = \"PDF Downloaded but Text Extraction Failed\"\n                except Exception as load_err:\n                    status = f\"PDF Downloaded but Text Loading Failed: {load_err}\"\n            else:\n                # Attempt 2: Check if it was HTML\n                if response_obj and response_obj.status_code == 200 and 'text/html' in response_obj.headers.get('Content-Type', '').lower():\n                    html_content = response_obj.text\n                    if len(html_content) > 200: # Basic check for valid content\n                        log.info(\"Direct download failed or not PDF, content is HTML.\")\n                        status = \"HTML Page Found\"\n                        # Attempt 2a: Find and download PDF from HTML\n                        pdf_path_from_html = find_and_download_pdf_from_html_internal(url, html_content, self.download_dir, self.timeout)\n                        if pdf_path_from_html:\n                            pdf_path = pdf_path_from_html # Assign for cleanup\n                            try:\n                                article_text, _ = load_pdf_text_internal(pdf_path)\n                                if article_text:\n                                    status = \"PDF Link in HTML Found, Downloaded & Text Loaded\"\n                                    source_type = \"PDF (from HTML link)\"\n                                else:\n                                    status = \"PDF via HTML Downloaded but Text Extraction Failed\"\n                            except Exception as load_err:\n                                status = f\"PDF via HTML Downloaded but Text Loading Failed: {load_err}\"\n                        else:\n                            # Attempt 2b: FALLBACK - Extract text directly from HTML\n                            log.info(\"Could not download PDF from HTML links. Attempting extraction from HTML text.\")\n                            status = \"HTML Scan Failed to Find PDF, Trying HTML Text Extraction\"\n                            article_text = extract_text_from_html_internal(html_content)\n                            if article_text:\n                                source_type = \"HTML\"\n                            else:\n                                status = \"HTML Scan Failed, HTML Text Extraction Failed\"\n                    else:\n                        status = \"HTML Page Found, but Content too small\"\n                elif response_obj:\n                     status = f\"Direct Download/Access Failed (Status: {response_obj.status_code}, Type: {response_obj.headers.get('Content-Type', 'N/A')})\"\n                else:\n                     status = \"Direct Download/Access Failed (Network/Request Error or Timeout)\"\n\n            # If text obtained, extract metrics\n            if article_text:\n                log.info(f\"Attempting metric extraction from {source_type} text...\")\n                extracted_data = self.metrics_extractor._run(text_content=article_text, source_type=source_type)\n                extraction_status = extracted_data.pop('status', 'Unknown Extraction Status')\n                status += f\" - {extraction_status}\"\n            else:\n                 log.info(\"No text loaded, skipping metric extraction.\")\n                 extracted_data = {key: 'No Text Loaded' for key in ['corrosion_inhibition_%', 'impedance_ohm_cm2', 'adhesion_MPa']}\n\n\n        except Exception as process_err:\n             log.error(f\"Unexpected error processing URL {url}: {type(process_err).__name__} - {process_err}\", exc_info=True) # Log full traceback here\n             status = f\"Unexpected Error During Processing: {type(process_err).__name__}\"\n             extracted_data = {key: 'Processing Error' for key in ['corrosion_inhibition_%', 'impedance_ohm_cm2', 'adhesion_MPa']}\n\n        finally:\n            final_result['status'] = status\n            # Merge extracted data into the final result\n            for key in ['corrosion_inhibition_%', 'impedance_ohm_cm2', 'adhesion_MPa']:\n                 final_result[key] = extracted_data.get(key, 'Error/Missing')\n\n            # Clean up temporary PDF file\n            if pdf_path and os.path.exists(pdf_path):\n                try:\n                    os.remove(pdf_path)\n                    log.info(f\"Removed temporary file: {pdf_path}\")\n                except OSError as e:\n                    log.warning(f\"Error removing temporary file {pdf_path}: {e}\")\n\n        return final_result\n\n# --- Main Agent Function ---\n\ndef run_reviewer_agent(pdf_path, openai_api_key, output_dir, llm_model, max_search, max_process, timeout, max_extract_chars, agent_verbose=True):\n    \"\"\"\n    Sets up and runs the LangChain Reviewer Assistant Agent.\n    \"\"\"\n    log.info(\"--- Starting Reviewer Assistant Agent ---\")\n\n    # --- Initialize LLM ---\n    try:\n        llm = ChatOpenAI(\n            temperature=0,\n            model_name=llm_model,\n            openai_api_key=openai_api_key,\n            request_timeout=180 # Increased timeout for agent chains\n        )\n        log.info(f\"LLM ({llm_model}) initialized.\")\n    except Exception as e:\n        log.critical(f\"Failed to initialize LLM: {e}. Please check API key and model name.\", exc_info=True)\n        return None # Indicate failure\n\n    # --- Create Temporary Directory for Downloads ---\n    # Use a context manager for automatic cleanup\n    with TemporaryDirectory(prefix=\"raa_downloads_\", dir=output_dir) as temp_download_dir:\n        log.info(f\"Using temporary download directory: {temp_download_dir}\")\n\n        # --- Instantiate Tools ---\n        load_tool = LoadManuscriptTool()\n        summarize_tool = SummarizeManuscriptTool(llm=llm)\n        extract_tool = ExtractMetricsTool(llm=llm)\n        search_tool = SearchSimilarArticlesTool()\n        process_article_tool = ProcessWebArticleTool(\n            metrics_extractor=extract_tool,\n            download_dir=temp_download_dir, # Use temp dir\n            timeout=timeout\n        )\n\n        tools = [load_tool, summarize_tool, extract_tool, search_tool, process_article_tool]\n\n        # --- Define Agent Prompt ---\n        prompt_template = ChatPromptTemplate.from_messages([\n            (\"system\",\n             \"You are a highly efficient Reviewer Assistant Agent. Your task is to analyze a scientific manuscript about corrosion inhibition and coatings. \"\n             \"Follow these steps precisely:\\n\"\n             # Step 1 Change: Mention 'docs_data' output\n             \"1. Load the manuscript PDF using the 'load_manuscript' tool using the provided path. This tool returns 'full_text' and 'docs_data' (a list of dicts).\\n\"\n             \"2. If loading is successful, extract the manuscript's title. Infer this from the first few pages' text in the 'full_text' field, or use the filename as a fallback. State the title clearly.\\n\"\n             # Step 3 Change: Mention using 'docs_data' as input\n             \"3. Summarize the manuscript's key findings using the 'summarize_manuscript' tool with the 'docs_data' field obtained from the load step.\\n\"\n             \"4. Extract the specific quantitative metrics (Corrosion Inhibition %, Impedance ohm.cm2, Adhesion MPa) from the 'full_text' of the manuscript using the 'extract_key_metrics' tool. Set source_type='Manuscript PDF' and use max_chars={max_extract_chars}.\\n\"\n             \"5. If a title was identified, search for similar articles online using 'search_similar_articles'. Use the manuscript title as the query and request {max_search_results} results.\\n\"\n             \"6. If search results (URLs) are found, process *up to* {max_process_limit} of the *most relevant-looking* URLs using the 'process_web_article' tool, one URL at a time. Prioritize URLs ending in .pdf or from known publishers (nature.com, sciencedirect.com, pubs.acs.org, mdpi.com, etc.). Skip obvious non-article links (e.g., search engine results pages).\\n\"\n             \"7. Compile ALL results into a single, final JSON object. The JSON object MUST have these top-level keys ONLY:\\n\"\n             \"   - 'manuscript_analysis': An object containing 'title', 'summary', and 'extracted_data' (the dict from step 4).\\n\"\n             \"   - 'similar_articles_analysis': A list of objects, where each object is the dictionary returned by 'process_web_article' for each processed URL (including 'url', 'status', 'corrosion_inhibition_%', 'impedance_ohm_cm2', 'adhesion_MPa').\\n\"\n             \"8. If any step fails (e.g., loading, search, processing a specific URL), report the error clearly in the 'status' or relevant field and proceed with the next steps if possible. The final JSON output is mandatory.\\n\"\n             \"9. Ensure your final response is ONLY the JSON object described in step 7, enclosed in ```json ... ```.\"\n             .format(max_search_results=max_search, max_process_limit=max_process, max_extract_chars=max_extract_chars)\n            ),\n            MessagesPlaceholder(variable_name=\"chat_history\"),\n            (\"human\", \"{input}\"),\n            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n        ])\n\n        # --- Create Agent and Executor ---\n        try:\n            agent = create_openai_functions_agent(llm, tools, prompt_template)\n            agent_executor = AgentExecutor(\n                agent=agent,\n                tools=tools,\n                verbose=agent_verbose,\n                handle_parsing_errors=True, # Try to recover from LLM format errors\n                max_iterations=25 # Increased slightly for multi-step processing\n            )\n            log.info(\"Agent setup complete.\")\n        except Exception as e:\n            log.critical(f\"Failed to create agent/executor: {e}\", exc_info=True)\n            return None # Indicate failure\n\n        # --- Prepare Input and Run Agent ---\n        initial_input = f\"Please process the manuscript located at '{pdf_path}' according to the standard procedure.\"\n        chat_history = []\n\n        try:\n            log.info(\"Invoking agent executor...\")\n            result = agent_executor.invoke({\"input\": initial_input, \"chat_history\": chat_history})\n            log.info(\"Agent execution finished.\")\n            agent_output = result.get('output', '{}')\n            return agent_output # Return the raw output string\n\n        except Exception as e:\n            log.critical(f\"An error occurred during agent execution: {type(e).__name__} - {e}\", exc_info=True)\n            # Optionally return partial results or a specific error structure\n            return json.dumps({\"error\": f\"Agent execution failed: {e}\"}) # Return error as JSON string\n\n    # End of TemporaryDirectory context - temp_download_dir is cleaned up here\n\n# --- Main Execution Block ---\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Reviewer Assistant Agent: Summarizes a manuscript and compares metrics with similar online articles.\")\n    # ...(keep all your parser.add_argument calls exactly as they were)...\n    parser.add_argument(\"pdf_path\", help=\"Path to the input manuscript PDF file.\")\n    parser.add_argument(\"-k\", \"--api-key\", help=\"OpenAI API Key. If not provided, uses OPENAI_API_KEY environment variable.\", default=None)\n    parser.add_argument(\"-o\", \"--output-dir\", help=\"Directory for temporary files (like downloads). Defaults to './raa_output'.\", default=\"./raa_output\")\n    parser.add_argument(\"--model\", help=f\"OpenAI model name to use. Defaults to '{DEFAULT_LLM_MODEL}'.\", default=DEFAULT_LLM_MODEL)\n    parser.add_argument(\"--max-search\", type=int, help=f\"Max Google search results. Defaults to {DEFAULT_MAX_SEARCH_RESULTS}.\", default=DEFAULT_MAX_SEARCH_RESULTS)\n    parser.add_argument(\"--max-process\", type=int, help=f\"Max similar articles to fully process. Defaults to {DEFAULT_MAX_SIMILAR_ARTICLES_TO_PROCESS}.\", default=DEFAULT_MAX_SIMILAR_ARTICLES_TO_PROCESS)\n    parser.add_argument(\"--timeout\", type=int, help=f\"Download timeout in seconds. Defaults to {DEFAULT_DOWNLOAD_TIMEOUT}.\", default=DEFAULT_DOWNLOAD_TIMEOUT)\n    parser.add_argument(\"--max-extract-chars\", type=int, help=f\"Max characters for LLM extraction. Defaults to {DEFAULT_MAX_CHARS_FOR_EXTRACTION}.\", default=DEFAULT_MAX_CHARS_FOR_EXTRACTION)\n    parser.add_argument(\"--quiet\", action=\"store_true\", help=\"Run agent silently (sets verbose=False).\")\n\n\n    # ----- MODIFICATION FOR NOTEBOOK -----\n    # Define arguments explicitly as a list of strings\n    # Replace placeholders with your actual values for notebook execution\n    pdf_file_to_process = \"/kaggle/input/sample-manuscript/Sample-Manuscript.pdf\" # <--- SET YOUR PDF PATH HERE\n    output_directory = \"/kaggle/working/raa_output\" # <--- SET YOUR DESIRED OUTPUT DIR HERE\n    # Add other arguments if needed, e.g., \"--model\", \"gpt-4\", \"--max-process\", \"3\"\n    # For boolean flags like --quiet, just include the flag string: \"--quiet\"\n\n    # Construct the argument list\n    args_list = [\n        pdf_file_to_process,\n        \"--output-dir\", output_directory,\n        \"--max-search\", \"20\",\n        \"--max-process\", \"10\",\n    ]\n\n    # Parse the explicit list instead of sys.argv\n    args = parser.parse_args(args_list)\n    # ----- END OF MODIFICATION -----\n\n\n    # --- Get API Key ---\n    # (Keep this section, it can still check args.api_key or environment variable)\n    openai_api_key = args.api_key or os.getenv(\"OPENAI_API_KEY\")\n    if not openai_api_key:\n        # If running in Kaggle, try getting from secrets as a fallback\n        try:\n            from kaggle_secrets import UserSecretsClient\n            user_secrets = UserSecretsClient()\n            openai_api_key = user_secrets.get_secret(\"OpenAI_API_KEY\")\n            log.info(\"Retrieved OpenAI API Key from Kaggle Secrets.\")\n            os.environ[\"OPENAI_API_KEY\"] = openai_api_key # Set env var too if needed later\n        except Exception as secret_err:\n            log.critical(f\"Kaggle Secrets error: {secret_err}\")\n            log.critical(\"Error: OpenAI API Key not found. Provide via --api-key, env var, or Kaggle Secrets.\")\n            exit(1) # Exit if key is definitely not found\n\n    if not openai_api_key: # Double check after trying secrets\n         log.critical(\"Error: OpenAI API Key not found. Provide via --api-key, env var, or Kaggle Secrets.\")\n         exit(1)\n\n\n    # --- Create Output Directory ---\n    os.makedirs(args.output_dir, exist_ok=True)\n    log.info(f\"Using output directory: {args.output_dir}\")\n\n    # --- Run the Agent ---\n    # (Keep the rest of the execution logic the same)\n    agent_raw_output = run_reviewer_agent(\n        pdf_path=args.pdf_path, # Uses the parsed path from args_list\n        openai_api_key=openai_api_key,\n        output_dir=args.output_dir,\n        llm_model=args.model,\n        max_search=args.max_search,\n        max_process=args.max_process,\n        timeout=args.timeout,\n        max_extract_chars=args.max_extract_chars,\n        agent_verbose=(not args.quiet)\n    )\n\n    \n    # --- Process and Display Results ---\n    if agent_raw_output:\n        print(\"\\n\" + \"=\"*30 + \" Agent Raw Output \" + \"=\"*30)\n        print(agent_raw_output)\n        print(\"=\"*76)\n\n        final_data = None\n        try:\n            # Attempt to extract JSON block\n            json_match = re.search(r\"```json\\n(.*?)\\n```\", agent_raw_output, re.DOTALL)\n            if json_match:\n                json_string = json_match.group(1)\n            else:\n                 # Fallback: assume the whole output might be JSON, clean it\n                 json_string = agent_raw_output.strip().strip('`')\n\n            final_data = json.loads(json_string)\n\n            print(\"\\n\\n\" + \"*\"*30 + \" Final Structured Results \" + \"*\"*30)\n\n            # Display Manuscript Info\n            manuscript_info = final_data.get('manuscript_analysis', {})\n            print(\"\\n--- Manuscript Analysis ---\")\n            print(f\"Title: {manuscript_info.get('title', 'N/A')}\")\n            print(\"Summary:\")\n            print(manuscript_info.get('summary', 'N/A'))\n            print(\"\\nExtracted Data:\")\n            ms_data = manuscript_info.get('extracted_data', {})\n            if 'error' in ms_data:\n                 print(f\"  Error extracting manuscript data: {ms_data['error']}\")\n            elif ms_data:\n                 # Create DataFrame for nice printing\n                 ms_df = pd.DataFrame([ms_data]) # Needs list of dicts\n                 print(ms_df.to_string(index=False))\n            else:\n                 print(\"  No manuscript data extracted.\")\n\n            # Display Similar Articles Info\n            similar_articles = final_data.get('similar_articles_analysis', [])\n            print(f\"\\n--- Similar Articles Analysis ({len(similar_articles)} URLs processed) ---\")\n            if similar_articles:\n                df_similar = pd.DataFrame(similar_articles)\n                column_order = ['url', 'status', 'corrosion_inhibition_%', 'impedance_ohm_cm2', 'adhesion_MPa']\n                # Ensure columns exist and are ordered correctly\n                df_similar = df_similar.reindex(columns=column_order, fill_value='N/A')\n\n                print(\"\\nResults Table:\")\n                # Use to_markdown for better terminal display\n                print(df_similar.to_markdown(index=False))\n\n                # Option: Save to CSV\n                csv_output_path = os.path.join(args.output_dir, \"similar_articles_data.csv\")\n                try:\n                    df_similar.to_csv(csv_output_path, index=False)\n                    print(f\"\\nSimilar articles data saved to: {csv_output_path}\")\n                except Exception as csv_e:\n                    print(f\"\\nWarning: Failed to save results to CSV: {csv_e}\")\n\n            else:\n                print(\"No data collected from similar articles (or none were processed/found).\")\n\n        except json.JSONDecodeError as json_err:\n            log.error(f\"Failed to parse the agent's final JSON output: {json_err}\")\n            print(\"\\n--- Error Parsing Agent's Final JSON Output ---\")\n            print(\"The agent likely failed to format its response correctly.\")\n            print(\"Check the 'Agent Raw Output' above for details.\")\n        except Exception as display_err:\n            log.error(f\"An error occurred while displaying results: {display_err}\", exc_info=True)\n            print(f\"\\n--- Error Displaying Results ---: {display_err}\")\n            if final_data: print(\"\\nRaw parsed data:\", final_data)\n\n    else:\n        print(\"\\n--- Agent execution failed. Check logs for details. ---\")\n    display(df_similar)\n\n    print(\"\\n--- Script Execution Finished ---\")\n\n# --- END OF FILE reviewer_agent_script.py ---","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-15T20:58:37.349277Z","iopub.execute_input":"2025-04-15T20:58:37.349648Z","iopub.status.idle":"2025-04-15T20:59:39.666276Z","shell.execute_reply.started":"2025-04-15T20:58:37.349625Z","shell.execute_reply":"2025-04-15T20:59:39.665314Z"}},"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m\nInvoking: `load_manuscript` with `{'pdf_path': '/kaggle/input/sample-manuscript/Sample-Manuscript.pdf'}`\n\n\n\u001b[0m\u001b[36;1m\u001b[1;3m{'full_text': 'Scrutinizing corrosion inhibition in acid solution, and the effect of inhibitors on the \\nperformance of polymer coatings on steel surface \\nM. Mahdavian1 \\nAbstract: \\nThis a sample manuscript created as an instance to use as an input for an GenAI model. The \\nGenAI model (gemini-1.5-pro-latest) is going to extract keywords based on corrosion \\ninhibitors (%), impedance (ohm.cm2), and adhesion strength (MPa). The title is going to use \\nin the top most relevant search results.  \\nThe azole-based corrosion inhibitor  in hydrochloric acid solution provides corrosion  \\ninhibition of 92% at concentration of 1000 ppm. The epoxy coated acid washed steel samples \\nrevealed an impedance of 2×10 8 ohm.cm2 and adhesion strength of 5.2 MPa after 20 days \\nsubjection to saline solution. \\n \\n \\n \\n \\n \\n \\n1 M. Mahdavian: LinkedIn Profile: https://www.linkedin.com/in/mohammad-mahdavian-\\n50827b53/', 'docs_data': [{'page_content': 'Scrutinizing corrosion inhibition in acid solution, and the effect of inhibitors on the \\nperformance of polymer coatings on steel surface \\nM. Mahdavian1 \\nAbstract: \\nThis a sample manuscript created as an instance to use as an input for an GenAI model. The \\nGenAI model (gemini-1.5-pro-latest) is going to extract keywords based on corrosion \\ninhibitors (%), impedance (ohm.cm2), and adhesion strength (MPa). The title is going to use \\nin the top most relevant search results.  \\nThe azole-based corrosion inhibitor  in hydrochloric acid solution provides corrosion  \\ninhibition of 92% at concentration of 1000 ppm. The epoxy coated acid washed steel samples \\nrevealed an impedance of 2×10 8 ohm.cm2 and adhesion strength of 5.2 MPa after 20 days \\nsubjection to saline solution. \\n \\n \\n \\n \\n \\n \\n1 M. Mahdavian: LinkedIn Profile: https://www.linkedin.com/in/mohammad-mahdavian-\\n50827b53/', 'metadata': {'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-04-06T23:42:00+03:30', 'author': 'Mohammad Mahdavian', 'moddate': '2025-04-06T23:42:00+03:30', 'source': '/kaggle/input/sample-manuscript/Sample-Manuscript.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}}]}\u001b[0m\u001b[32;1m\u001b[1;3m\nInvoking: `summarize_manuscript` with `{'docs_data': [{'page_content': 'Scrutinizing corrosion inhibition in acid solution, and the effect of inhibitors on the \\nperformance of polymer coatings on steel surface \\nM. Mahdavian1 \\nAbstract: \\nThis a sample manuscript created as an instance to use as an input for an GenAI model. The \\nGenAI model (gemini-1.5-pro-latest) is going to extract keywords based on corrosion \\ninhibitors (%), impedance (ohm.cm2), and adhesion strength (MPa). The title is going to use \\nin the top most relevant search results.  \\nThe azole-based corrosion inhibitor  in hydrochloric acid solution provides corrosion  \\ninhibition of 92% at concentration of 1000 ppm. The epoxy coated acid washed steel samples \\nrevealed an impedance of 2×10 8 ohm.cm2 and adhesion strength of 5.2 MPa after 20 days \\nsubjection to saline solution. \\n \\n \\n \\n \\n \\n \\n1 M. Mahdavian: LinkedIn Profile: https://www.linkedin.com/in/mohammad-mahdavian-\\n50827b53/', 'metadata': {'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-04-06T23:42:00+03:30', 'author': 'Mohammad Mahdavian', 'moddate': '2025-04-06T23:42:00+03:30', 'source': '/kaggle/input/sample-manuscript/Sample-Manuscript.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}}]}`\n\n\n\u001b[0m\u001b[33;1m\u001b[1;3mThe study demonstrates that an azole-based corrosion inhibitor achieves 92% inhibition in hydrochloric acid at 1000 ppm and enhances epoxy-coated steel's corrosion resistance and adhesion in saline, evidenced by high impedance and strong adhesion after 20 days.\u001b[0m\u001b[32;1m\u001b[1;3m\nInvoking: `extract_key_metrics` with `{'text_content': 'Scrutinizing corrosion inhibition in acid solution, and the effect of inhibitors on the \\nperformance of polymer coatings on steel surface \\nM. Mahdavian1 \\nAbstract: \\nThis a sample manuscript created as an instance to use as an input for an GenAI model. The \\nGenAI model (gemini-1.5-pro-latest) is going to extract keywords based on corrosion \\ninhibitors (%), impedance (ohm.cm2), and adhesion strength (MPa). The title is going to use \\nin the top most relevant search results.  \\nThe azole-based corrosion inhibitor  in hydrochloric acid solution provides corrosion  \\ninhibition of 92% at concentration of 1000 ppm. The epoxy coated acid washed steel samples \\nrevealed an impedance of 2×10 8 ohm.cm2 and adhesion strength of 5.2 MPa after 20 days \\nsubjection to saline solution.', 'source_type': 'Manuscript PDF', 'max_chars': 25000}`\n\n\n\u001b[0m\u001b[38;5;200m\u001b[1;3m{'corrosion_inhibition_%': '92', 'impedance_ohm_cm2': '2×10 8 ohm.cm2 (parsed num: 2)', 'adhesion_MPa': '5.2', 'status': 'Extraction Successful (Found Values)'}\u001b[0m\u001b[32;1m\u001b[1;3m\nInvoking: `search_similar_articles` with `{'query': 'Scrutinizing corrosion inhibition in acid solution, and the effect of inhibitors on the performance of polymer coatings on steel surface', 'num_results': 20}`\n\n\n\u001b[0m\u001b[36;1m\u001b[1;3m{'urls': ['https://link.springer.com/article/10.1007/s11696-024-03503-5', 'https://www.sciencedirect.com/science/article/pii/S2666845924000783', 'https://www.sciencedirect.com/science/article/pii/S2667266924000410', 'https://link.springer.com/article/10.1007/s11998-020-00426-0', 'https://pdfs.semanticscholar.org/bc32/93e4080d337d871034df39ab78c16e9d4180.pdf', 'https://www.sciencedirect.com/science/article/pii/S0167732218312856', 'https://chemistry-europe.onlinelibrary.wiley.com/doi/10.1002/celc.202400515', 'https://www.nature.com/articles/s41598-025-93419-1', 'https://link.springer.com/article/10.1007/s10853-025-10843-4', 'https://pubs.acs.org/doi/10.1021/acsomega.0c05476', 'https://www.sciencedirect.com/science/article/pii/S2589234720300130', 'https://onlinelibrary.wiley.com/doi/full/10.1002/vjch.202200111', 'https://www.sciencedirect.com/science/article/pii/S037967792100028X', 'https://www.researchgate.net/publication/368919064_Corrosion_inhibitors_for_carbon_steel_A_review', 'https://www.sciencedirect.com/science/article/pii/S1385894722045223', 'https://www.sciencedirect.com/science/article/pii/S016773222037104X', 'https://www.researchgate.net/publication/349645144_Corrosion_inhibitors_A_review', 'https://www.sciencedirect.com/science/article/pii/S0257897214005428', 'https://www.mdpi.com/1996-1944/16/8/2954', 'https://www.sciencedirect.com/science/article/pii/S1385894721030618']}\u001b[0m\u001b[32;1m\u001b[1;3m\nInvoking: `process_web_article` with `{'url': 'https://link.springer.com/article/10.1007/s11696-024-03503-5'}`\n\n\n\u001b[0m\u001b[33;1m\u001b[1;3m{'url': 'https://link.springer.com/article/10.1007/s11696-024-03503-5', 'status': 'HTML Scan Failed to Find PDF, Trying HTML Text Extraction - Extraction Successful (Found Values)', 'corrosion_inhibition_%': 'Not Found', 'impedance_ohm_cm2': 'Not Found', 'adhesion_MPa': 'Not Found'}\u001b[0m\u001b[32;1m\u001b[1;3m\nInvoking: `process_web_article` with `{'url': 'https://www.sciencedirect.com/science/article/pii/S2666845924000783'}`\n\n\n\u001b[0m\u001b[33;1m\u001b[1;3m{'url': 'https://www.sciencedirect.com/science/article/pii/S2666845924000783', 'status': 'Direct Download/Access Failed (Network/Request Error or Timeout)', 'corrosion_inhibition_%': 'No Text Loaded', 'impedance_ohm_cm2': 'No Text Loaded', 'adhesion_MPa': 'No Text Loaded'}\u001b[0m\u001b[32;1m\u001b[1;3m\nInvoking: `process_web_article` with `{'url': 'https://www.sciencedirect.com/science/article/pii/S2667266924000410'}`\n\n\n\u001b[0m\u001b[33;1m\u001b[1;3m{'url': 'https://www.sciencedirect.com/science/article/pii/S2667266924000410', 'status': 'Direct Download/Access Failed (Network/Request Error or Timeout)', 'corrosion_inhibition_%': 'No Text Loaded', 'impedance_ohm_cm2': 'No Text Loaded', 'adhesion_MPa': 'No Text Loaded'}\u001b[0m\u001b[32;1m\u001b[1;3m\nInvoking: `process_web_article` with `{'url': 'https://link.springer.com/article/10.1007/s11998-020-00426-0'}`\n\n\n\u001b[0m\u001b[33;1m\u001b[1;3m{'url': 'https://link.springer.com/article/10.1007/s11998-020-00426-0', 'status': 'HTML Scan Failed to Find PDF, Trying HTML Text Extraction - Extraction Successful (Found Values)', 'corrosion_inhibition_%': 'Not Found', 'impedance_ohm_cm2': 'Not Found', 'adhesion_MPa': 'Not Found'}\u001b[0m\u001b[32;1m\u001b[1;3m\nInvoking: `process_web_article` with `{'url': 'https://pdfs.semanticscholar.org/bc32/93e4080d337d871034df39ab78c16e9d4180.pdf'}`\n\n\n\u001b[0m\u001b[33;1m\u001b[1;3m{'url': 'https://pdfs.semanticscholar.org/bc32/93e4080d337d871034df39ab78c16e9d4180.pdf', 'status': 'PDF Downloaded & Text Loaded - Extraction Successful (Found Values)', 'corrosion_inhibition_%': '99.75', 'impedance_ohm_cm2': 'Not Found', 'adhesion_MPa': 'Not Found'}\u001b[0m\u001b[32;1m\u001b[1;3m\nInvoking: `process_web_article` with `{'url': 'https://www.sciencedirect.com/science/article/pii/S0167732218312856'}`\n\n\n\u001b[0m\u001b[33;1m\u001b[1;3m{'url': 'https://www.sciencedirect.com/science/article/pii/S0167732218312856', 'status': 'Direct Download/Access Failed (Network/Request Error or Timeout)', 'corrosion_inhibition_%': 'No Text Loaded', 'impedance_ohm_cm2': 'No Text Loaded', 'adhesion_MPa': 'No Text Loaded'}\u001b[0m\u001b[32;1m\u001b[1;3m\nInvoking: `process_web_article` with `{'url': 'https://chemistry-europe.onlinelibrary.wiley.com/doi/10.1002/celc.202400515'}`\n\n\n\u001b[0m\u001b[33;1m\u001b[1;3m{'url': 'https://chemistry-europe.onlinelibrary.wiley.com/doi/10.1002/celc.202400515', 'status': 'Direct Download/Access Failed (Network/Request Error or Timeout)', 'corrosion_inhibition_%': 'No Text Loaded', 'impedance_ohm_cm2': 'No Text Loaded', 'adhesion_MPa': 'No Text Loaded'}\u001b[0m\u001b[32;1m\u001b[1;3m\nInvoking: `process_web_article` with `{'url': 'https://www.nature.com/articles/s41598-025-93419-1'}`\n\n\n\u001b[0m\u001b[33;1m\u001b[1;3m{'url': 'https://www.nature.com/articles/s41598-025-93419-1', 'status': 'PDF Link in HTML Found, Downloaded & Text Loaded - Extraction Successful (Found Values)', 'corrosion_inhibition_%': '94.9', 'impedance_ohm_cm2': 'Not Found', 'adhesion_MPa': 'Not Found'}\u001b[0m\u001b[32;1m\u001b[1;3m\nInvoking: `process_web_article` with `{'url': 'https://link.springer.com/article/10.1007/s10853-025-10843-4'}`\n\n\n\u001b[0m\u001b[33;1m\u001b[1;3m{'url': 'https://link.springer.com/article/10.1007/s10853-025-10843-4', 'status': 'HTML Scan Failed to Find PDF, Trying HTML Text Extraction - Extraction Successful (Found Values)', 'corrosion_inhibition_%': 'Not Found', 'impedance_ohm_cm2': '3 orders of magnitude higher than EP after 35 days (exact value Not Found) (parsed num: 3)', 'adhesion_MPa': 'Not Found'}\u001b[0m\u001b[32;1m\u001b[1;3m\nInvoking: `process_web_article` with `{'url': 'https://pubs.acs.org/doi/10.1021/acsomega.0c05476'}`\n\n\n\u001b[0m\u001b[33;1m\u001b[1;3m{'url': 'https://pubs.acs.org/doi/10.1021/acsomega.0c05476', 'status': 'Direct Download/Access Failed (Network/Request Error or Timeout)', 'corrosion_inhibition_%': 'No Text Loaded', 'impedance_ohm_cm2': 'No Text Loaded', 'adhesion_MPa': 'No Text Loaded'}\u001b[0m\u001b[32;1m\u001b[1;3m\nInvoking: `process_web_article` with `{'url': 'https://www.sciencedirect.com/science/article/pii/S2589234720300130'}`\n\n\n\u001b[0m\u001b[33;1m\u001b[1;3m{'url': 'https://www.sciencedirect.com/science/article/pii/S2589234720300130', 'status': 'Direct Download/Access Failed (Network/Request Error or Timeout)', 'corrosion_inhibition_%': 'No Text Loaded', 'impedance_ohm_cm2': 'No Text Loaded', 'adhesion_MPa': 'No Text Loaded'}\u001b[0m\u001b[32;1m\u001b[1;3m```json\n{\n  \"manuscript_analysis\": {\n    \"title\": \"Scrutinizing corrosion inhibition in acid solution, and the effect of inhibitors on the performance of polymer coatings on steel surface\",\n    \"summary\": \"The study demonstrates that an azole-based corrosion inhibitor achieves 92% inhibition in hydrochloric acid at 1000 ppm and enhances epoxy-coated steel's corrosion resistance and adhesion in saline, evidenced by high impedance and strong adhesion after 20 days.\",\n    \"extracted_data\": {\n      \"corrosion_inhibition_%\": \"92\",\n      \"impedance_ohm_cm2\": \"2×10 8 ohm.cm2 (parsed num: 2)\",\n      \"adhesion_MPa\": \"5.2\",\n      \"status\": \"Extraction Successful (Found Values)\"\n    }\n  },\n  \"similar_articles_analysis\": [\n    {\n      \"url\": \"https://link.springer.com/article/10.1007/s11696-024-03503-5\",\n      \"status\": \"HTML Scan Failed to Find PDF, Trying HTML Text Extraction - Extraction Successful (Found Values)\",\n      \"corrosion_inhibition_%\": \"Not Found\",\n      \"impedance_ohm_cm2\": \"Not Found\",\n      \"adhesion_MPa\": \"Not Found\"\n    },\n    {\n      \"url\": \"https://www.sciencedirect.com/science/article/pii/S2666845924000783\",\n      \"status\": \"Direct Download/Access Failed (Network/Request Error or Timeout)\",\n      \"corrosion_inhibition_%\": \"No Text Loaded\",\n      \"impedance_ohm_cm2\": \"No Text Loaded\",\n      \"adhesion_MPa\": \"No Text Loaded\"\n    },\n    {\n      \"url\": \"https://www.sciencedirect.com/science/article/pii/S2667266924000410\",\n      \"status\": \"Direct Download/Access Failed (Network/Request Error or Timeout)\",\n      \"corrosion_inhibition_%\": \"No Text Loaded\",\n      \"impedance_ohm_cm2\": \"No Text Loaded\",\n      \"adhesion_MPa\": \"No Text Loaded\"\n    },\n    {\n      \"url\": \"https://link.springer.com/article/10.1007/s11998-020-00426-0\",\n      \"status\": \"HTML Scan Failed to Find PDF, Trying HTML Text Extraction - Extraction Successful (Found Values)\",\n      \"corrosion_inhibition_%\": \"Not Found\",\n      \"impedance_ohm_cm2\": \"Not Found\",\n      \"adhesion_MPa\": \"Not Found\"\n    },\n    {\n      \"url\": \"https://pdfs.semanticscholar.org/bc32/93e4080d337d871034df39ab78c16e9d4180.pdf\",\n      \"status\": \"PDF Downloaded & Text Loaded - Extraction Successful (Found Values)\",\n      \"corrosion_inhibition_%\": \"99.75\",\n      \"impedance_ohm_cm2\": \"Not Found\",\n      \"adhesion_MPa\": \"Not Found\"\n    },\n    {\n      \"url\": \"https://www.sciencedirect.com/science/article/pii/S0167732218312856\",\n      \"status\": \"Direct Download/Access Failed (Network/Request Error or Timeout)\",\n      \"corrosion_inhibition_%\": \"No Text Loaded\",\n      \"impedance_ohm_cm2\": \"No Text Loaded\",\n      \"adhesion_MPa\": \"No Text Loaded\"\n    },\n    {\n      \"url\": \"https://chemistry-europe.onlinelibrary.wiley.com/doi/10.1002/celc.202400515\",\n      \"status\": \"Direct Download/Access Failed (Network/Request Error or Timeout)\",\n      \"corrosion_inhibition_%\": \"No Text Loaded\",\n      \"impedance_ohm_cm2\": \"No Text Loaded\",\n      \"adhesion_MPa\": \"No Text Loaded\"\n    },\n    {\n      \"url\": \"https://www.nature.com/articles/s41598-025-93419-1\",\n      \"status\": \"PDF Link in HTML Found, Downloaded & Text Loaded - Extraction Successful (Found Values)\",\n      \"corrosion_inhibition_%\": \"94.9\",\n      \"impedance_ohm_cm2\": \"Not Found\",\n      \"adhesion_MPa\": \"Not Found\"\n    },\n    {\n      \"url\": \"https://link.springer.com/article/10.1007/s10853-025-10843-4\",\n      \"status\": \"HTML Scan Failed to Find PDF, Trying HTML Text Extraction - Extraction Successful (Found Values)\",\n      \"corrosion_inhibition_%\": \"Not Found\",\n      \"impedance_ohm_cm2\": \"3 orders of magnitude higher than EP after 35 days (exact value Not Found) (parsed num: 3)\",\n      \"adhesion_MPa\": \"Not Found\"\n    },\n    {\n      \"url\": \"https://pubs.acs.org/doi/10.1021/acsomega.0c05476\",\n      \"status\": \"Direct Download/Access Failed (Network/Request Error or Timeout)\",\n      \"corrosion_inhibition_%\": \"No Text Loaded\",\n      \"impedance_ohm_cm2\": \"No Text Loaded\",\n      \"adhesion_MPa\": \"No Text Loaded\"\n    }\n  ]\n}\n```\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n\n============================== Agent Raw Output ==============================\n```json\n{\n  \"manuscript_analysis\": {\n    \"title\": \"Scrutinizing corrosion inhibition in acid solution, and the effect of inhibitors on the performance of polymer coatings on steel surface\",\n    \"summary\": \"The study demonstrates that an azole-based corrosion inhibitor achieves 92% inhibition in hydrochloric acid at 1000 ppm and enhances epoxy-coated steel's corrosion resistance and adhesion in saline, evidenced by high impedance and strong adhesion after 20 days.\",\n    \"extracted_data\": {\n      \"corrosion_inhibition_%\": \"92\",\n      \"impedance_ohm_cm2\": \"2×10 8 ohm.cm2 (parsed num: 2)\",\n      \"adhesion_MPa\": \"5.2\",\n      \"status\": \"Extraction Successful (Found Values)\"\n    }\n  },\n  \"similar_articles_analysis\": [\n    {\n      \"url\": \"https://link.springer.com/article/10.1007/s11696-024-03503-5\",\n      \"status\": \"HTML Scan Failed to Find PDF, Trying HTML Text Extraction - Extraction Successful (Found Values)\",\n      \"corrosion_inhibition_%\": \"Not Found\",\n      \"impedance_ohm_cm2\": \"Not Found\",\n      \"adhesion_MPa\": \"Not Found\"\n    },\n    {\n      \"url\": \"https://www.sciencedirect.com/science/article/pii/S2666845924000783\",\n      \"status\": \"Direct Download/Access Failed (Network/Request Error or Timeout)\",\n      \"corrosion_inhibition_%\": \"No Text Loaded\",\n      \"impedance_ohm_cm2\": \"No Text Loaded\",\n      \"adhesion_MPa\": \"No Text Loaded\"\n    },\n    {\n      \"url\": \"https://www.sciencedirect.com/science/article/pii/S2667266924000410\",\n      \"status\": \"Direct Download/Access Failed (Network/Request Error or Timeout)\",\n      \"corrosion_inhibition_%\": \"No Text Loaded\",\n      \"impedance_ohm_cm2\": \"No Text Loaded\",\n      \"adhesion_MPa\": \"No Text Loaded\"\n    },\n    {\n      \"url\": \"https://link.springer.com/article/10.1007/s11998-020-00426-0\",\n      \"status\": \"HTML Scan Failed to Find PDF, Trying HTML Text Extraction - Extraction Successful (Found Values)\",\n      \"corrosion_inhibition_%\": \"Not Found\",\n      \"impedance_ohm_cm2\": \"Not Found\",\n      \"adhesion_MPa\": \"Not Found\"\n    },\n    {\n      \"url\": \"https://pdfs.semanticscholar.org/bc32/93e4080d337d871034df39ab78c16e9d4180.pdf\",\n      \"status\": \"PDF Downloaded & Text Loaded - Extraction Successful (Found Values)\",\n      \"corrosion_inhibition_%\": \"99.75\",\n      \"impedance_ohm_cm2\": \"Not Found\",\n      \"adhesion_MPa\": \"Not Found\"\n    },\n    {\n      \"url\": \"https://www.sciencedirect.com/science/article/pii/S0167732218312856\",\n      \"status\": \"Direct Download/Access Failed (Network/Request Error or Timeout)\",\n      \"corrosion_inhibition_%\": \"No Text Loaded\",\n      \"impedance_ohm_cm2\": \"No Text Loaded\",\n      \"adhesion_MPa\": \"No Text Loaded\"\n    },\n    {\n      \"url\": \"https://chemistry-europe.onlinelibrary.wiley.com/doi/10.1002/celc.202400515\",\n      \"status\": \"Direct Download/Access Failed (Network/Request Error or Timeout)\",\n      \"corrosion_inhibition_%\": \"No Text Loaded\",\n      \"impedance_ohm_cm2\": \"No Text Loaded\",\n      \"adhesion_MPa\": \"No Text Loaded\"\n    },\n    {\n      \"url\": \"https://www.nature.com/articles/s41598-025-93419-1\",\n      \"status\": \"PDF Link in HTML Found, Downloaded & Text Loaded - Extraction Successful (Found Values)\",\n      \"corrosion_inhibition_%\": \"94.9\",\n      \"impedance_ohm_cm2\": \"Not Found\",\n      \"adhesion_MPa\": \"Not Found\"\n    },\n    {\n      \"url\": \"https://link.springer.com/article/10.1007/s10853-025-10843-4\",\n      \"status\": \"HTML Scan Failed to Find PDF, Trying HTML Text Extraction - Extraction Successful (Found Values)\",\n      \"corrosion_inhibition_%\": \"Not Found\",\n      \"impedance_ohm_cm2\": \"3 orders of magnitude higher than EP after 35 days (exact value Not Found) (parsed num: 3)\",\n      \"adhesion_MPa\": \"Not Found\"\n    },\n    {\n      \"url\": \"https://pubs.acs.org/doi/10.1021/acsomega.0c05476\",\n      \"status\": \"Direct Download/Access Failed (Network/Request Error or Timeout)\",\n      \"corrosion_inhibition_%\": \"No Text Loaded\",\n      \"impedance_ohm_cm2\": \"No Text Loaded\",\n      \"adhesion_MPa\": \"No Text Loaded\"\n    }\n  ]\n}\n```\n============================================================================\n\n\n****************************** Final Structured Results ******************************\n\n--- Manuscript Analysis ---\nTitle: Scrutinizing corrosion inhibition in acid solution, and the effect of inhibitors on the performance of polymer coatings on steel surface\nSummary:\nThe study demonstrates that an azole-based corrosion inhibitor achieves 92% inhibition in hydrochloric acid at 1000 ppm and enhances epoxy-coated steel's corrosion resistance and adhesion in saline, evidenced by high impedance and strong adhesion after 20 days.\n\nExtracted Data:\ncorrosion_inhibition_%              impedance_ohm_cm2 adhesion_MPa                               status\n                    92 2×10 8 ohm.cm2 (parsed num: 2)          5.2 Extraction Successful (Found Values)\n\n--- Similar Articles Analysis (10 URLs processed) ---\n\nResults Table:\n| url                                                                            | status                                                                                           | corrosion_inhibition_%   | impedance_ohm_cm2                                                                          | adhesion_MPa   |\n|:-------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------|:-------------------------|:-------------------------------------------------------------------------------------------|:---------------|\n| https://link.springer.com/article/10.1007/s11696-024-03503-5                   | HTML Scan Failed to Find PDF, Trying HTML Text Extraction - Extraction Successful (Found Values) | Not Found                | Not Found                                                                                  | Not Found      |\n| https://www.sciencedirect.com/science/article/pii/S2666845924000783            | Direct Download/Access Failed (Network/Request Error or Timeout)                                 | No Text Loaded           | No Text Loaded                                                                             | No Text Loaded |\n| https://www.sciencedirect.com/science/article/pii/S2667266924000410            | Direct Download/Access Failed (Network/Request Error or Timeout)                                 | No Text Loaded           | No Text Loaded                                                                             | No Text Loaded |\n| https://link.springer.com/article/10.1007/s11998-020-00426-0                   | HTML Scan Failed to Find PDF, Trying HTML Text Extraction - Extraction Successful (Found Values) | Not Found                | Not Found                                                                                  | Not Found      |\n| https://pdfs.semanticscholar.org/bc32/93e4080d337d871034df39ab78c16e9d4180.pdf | PDF Downloaded & Text Loaded - Extraction Successful (Found Values)                              | 99.75                    | Not Found                                                                                  | Not Found      |\n| https://www.sciencedirect.com/science/article/pii/S0167732218312856            | Direct Download/Access Failed (Network/Request Error or Timeout)                                 | No Text Loaded           | No Text Loaded                                                                             | No Text Loaded |\n| https://chemistry-europe.onlinelibrary.wiley.com/doi/10.1002/celc.202400515    | Direct Download/Access Failed (Network/Request Error or Timeout)                                 | No Text Loaded           | No Text Loaded                                                                             | No Text Loaded |\n| https://www.nature.com/articles/s41598-025-93419-1                             | PDF Link in HTML Found, Downloaded & Text Loaded - Extraction Successful (Found Values)          | 94.9                     | Not Found                                                                                  | Not Found      |\n| https://link.springer.com/article/10.1007/s10853-025-10843-4                   | HTML Scan Failed to Find PDF, Trying HTML Text Extraction - Extraction Successful (Found Values) | Not Found                | 3 orders of magnitude higher than EP after 35 days (exact value Not Found) (parsed num: 3) | Not Found      |\n| https://pubs.acs.org/doi/10.1021/acsomega.0c05476                              | Direct Download/Access Failed (Network/Request Error or Timeout)                                 | No Text Loaded           | No Text Loaded                                                                             | No Text Loaded |\n\nSimilar articles data saved to: /kaggle/working/raa_output/similar_articles_data.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                 url  \\\n0  https://link.springer.com/article/10.1007/s116...   \n1  https://www.sciencedirect.com/science/article/...   \n2  https://www.sciencedirect.com/science/article/...   \n3  https://link.springer.com/article/10.1007/s119...   \n4  https://pdfs.semanticscholar.org/bc32/93e4080d...   \n5  https://www.sciencedirect.com/science/article/...   \n6  https://chemistry-europe.onlinelibrary.wiley.c...   \n7  https://www.nature.com/articles/s41598-025-934...   \n8  https://link.springer.com/article/10.1007/s108...   \n9  https://pubs.acs.org/doi/10.1021/acsomega.0c05476   \n\n                                              status corrosion_inhibition_%  \\\n0  HTML Scan Failed to Find PDF, Trying HTML Text...              Not Found   \n1  Direct Download/Access Failed (Network/Request...         No Text Loaded   \n2  Direct Download/Access Failed (Network/Request...         No Text Loaded   \n3  HTML Scan Failed to Find PDF, Trying HTML Text...              Not Found   \n4  PDF Downloaded & Text Loaded - Extraction Succ...                  99.75   \n5  Direct Download/Access Failed (Network/Request...         No Text Loaded   \n6  Direct Download/Access Failed (Network/Request...         No Text Loaded   \n7  PDF Link in HTML Found, Downloaded & Text Load...                   94.9   \n8  HTML Scan Failed to Find PDF, Trying HTML Text...              Not Found   \n9  Direct Download/Access Failed (Network/Request...         No Text Loaded   \n\n                                   impedance_ohm_cm2    adhesion_MPa  \n0                                          Not Found       Not Found  \n1                                     No Text Loaded  No Text Loaded  \n2                                     No Text Loaded  No Text Loaded  \n3                                          Not Found       Not Found  \n4                                          Not Found       Not Found  \n5                                     No Text Loaded  No Text Loaded  \n6                                     No Text Loaded  No Text Loaded  \n7                                          Not Found       Not Found  \n8  3 orders of magnitude higher than EP after 35 ...       Not Found  \n9                                     No Text Loaded  No Text Loaded  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>status</th>\n      <th>corrosion_inhibition_%</th>\n      <th>impedance_ohm_cm2</th>\n      <th>adhesion_MPa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://link.springer.com/article/10.1007/s116...</td>\n      <td>HTML Scan Failed to Find PDF, Trying HTML Text...</td>\n      <td>Not Found</td>\n      <td>Not Found</td>\n      <td>Not Found</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.sciencedirect.com/science/article/...</td>\n      <td>Direct Download/Access Failed (Network/Request...</td>\n      <td>No Text Loaded</td>\n      <td>No Text Loaded</td>\n      <td>No Text Loaded</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.sciencedirect.com/science/article/...</td>\n      <td>Direct Download/Access Failed (Network/Request...</td>\n      <td>No Text Loaded</td>\n      <td>No Text Loaded</td>\n      <td>No Text Loaded</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://link.springer.com/article/10.1007/s119...</td>\n      <td>HTML Scan Failed to Find PDF, Trying HTML Text...</td>\n      <td>Not Found</td>\n      <td>Not Found</td>\n      <td>Not Found</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://pdfs.semanticscholar.org/bc32/93e4080d...</td>\n      <td>PDF Downloaded &amp; Text Loaded - Extraction Succ...</td>\n      <td>99.75</td>\n      <td>Not Found</td>\n      <td>Not Found</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>https://www.sciencedirect.com/science/article/...</td>\n      <td>Direct Download/Access Failed (Network/Request...</td>\n      <td>No Text Loaded</td>\n      <td>No Text Loaded</td>\n      <td>No Text Loaded</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>https://chemistry-europe.onlinelibrary.wiley.c...</td>\n      <td>Direct Download/Access Failed (Network/Request...</td>\n      <td>No Text Loaded</td>\n      <td>No Text Loaded</td>\n      <td>No Text Loaded</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>https://www.nature.com/articles/s41598-025-934...</td>\n      <td>PDF Link in HTML Found, Downloaded &amp; Text Load...</td>\n      <td>94.9</td>\n      <td>Not Found</td>\n      <td>Not Found</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>https://link.springer.com/article/10.1007/s108...</td>\n      <td>HTML Scan Failed to Find PDF, Trying HTML Text...</td>\n      <td>Not Found</td>\n      <td>3 orders of magnitude higher than EP after 35 ...</td>\n      <td>Not Found</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>https://pubs.acs.org/doi/10.1021/acsomega.0c05476</td>\n      <td>Direct Download/Access Failed (Network/Request...</td>\n      <td>No Text Loaded</td>\n      <td>No Text Loaded</td>\n      <td>No Text Loaded</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n--- Script Execution Finished ---\n","output_type":"stream"}],"execution_count":7}]}